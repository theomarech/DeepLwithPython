{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "altered-national",
   "metadata": {},
   "source": [
    "# CHPT IV - EVALUATION DES MODELES\n",
    "\n",
    "Objectif : trois techniques pour évaluer les modèles afin d'optimiser leur trade off biais/variance\n",
    "- avoir un modèles qui minimise/maximise un score\n",
    "- sur les données de test\n",
    "- sans les avoir vue au préalable\n",
    "\n",
    "Trois techniques :\n",
    "- simple hold-out validation = un training set splitté en training/validation et un test qu'on n'utilisera seulement avant la mise en production\n",
    "- shuffle hold-out avec iteration = on shuffle les données d'entrainement : on splitte train/validation on calcul l'erreur et on recommence...\n",
    "- KFOLD = dans le cas de petit jeux de données ou simplement dans le cas d'une variance forte dans le premier cas : on divise notre jeux de données en K partie de même taille, chaque partie sera prise comme jeux de données de validation et d'entrainement, les scores pourront alors être moyennée\n",
    "- KFOLD + shuffle iteration = les deux dernière technique, très bien pour les petits jeux de données mais très couteux en temps de calcul...\n",
    "\n",
    "## Préparation des données et du modèles sur les données imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "employed-exclusion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "mounted-muscle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras import models, layers\n",
    "import numpy as np\n",
    "\n",
    "#ouverture\n",
    "(train_data,train_labels),(test_data,test_labels) = imdb.load_data(num_words=10000)\n",
    "\n",
    "#prépa des données train et test\n",
    "def vectorize_data(data,dim=10000):\n",
    "    results = np.zeros((len(data),dim))\n",
    "    for i, word in enumerate(data):\n",
    "        results[i,word] = 1\n",
    "    return results\n",
    "\n",
    "x_train = vectorize_data(train_data)\n",
    "x_test = vectorize_data(test_data)\n",
    "\n",
    "y_train = np.asarray(train_labels).astype(float)\n",
    "y_test = np.asarray(test_labels).astype(float)\n",
    "\n",
    "# réseaux de neurones\n",
    "\n",
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(16,activation = \"relu\",input_shape = (10000,)))\n",
    "    model.add(layers.Dense(16,activation = \"relu\"))\n",
    "    model.add(layers.Dense(1, activation = \"sigmoid\"))\n",
    "    \n",
    "    model.compile(optimizer = \"rmsprop\",\n",
    "                  loss = \"binary_crossentropy\",\n",
    "                  metrics = [\"accuracy\"])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "golden-rocket",
   "metadata": {},
   "source": [
    "## Simple hold-out validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "challenging-yacht",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "37/37 [==============================] - 1s 28ms/step - loss: 0.6937 - accuracy: 0.4964 - val_loss: 0.6932 - val_accuracy: 0.4982\n",
      "Epoch 2/5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 0.6791 - accuracy: 0.5825 - val_loss: 0.7016 - val_accuracy: 0.4934\n",
      "Epoch 3/5\n",
      "37/37 [==============================] - 1s 19ms/step - loss: 0.6401 - accuracy: 0.6603 - val_loss: 0.7090 - val_accuracy: 0.5019\n",
      "Epoch 4/5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 0.5917 - accuracy: 0.7155 - val_loss: 0.7249 - val_accuracy: 0.5010\n",
      "Epoch 5/5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 0.5428 - accuracy: 0.7499 - val_loss: 0.7511 - val_accuracy: 0.5005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cc811a64f0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.shuffle(x_train) # on mélange le jeux de données\n",
    "\n",
    "p = 0.75\n",
    "l = len(x_train)\n",
    "size = round(p*l)\n",
    "\n",
    "x_ent = x_train[:size]\n",
    "y_ent = y_train[:size]\n",
    "\n",
    "x_val = x_train[size:]\n",
    "y_val = y_train[size:]\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "model.fit(x_ent,\n",
    "          y_ent,\n",
    "          epochs=5,\n",
    "          batch_size=512,\n",
    "         validation_data=(x_val,y_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
