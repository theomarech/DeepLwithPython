{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c91e7fa-d91f-4be1-9531-f63418f06070",
   "metadata": {},
   "source": [
    "# CHPT5 - Comment faire avec un petit jeu de données d'images ?\n",
    "- apprentissage avec un CNN à partir de zéros\n",
    "- augmentation de données\n",
    "- utilisation d'un réseau pré-entrainé\n",
    "- paramétrisation du réseau\n",
    "\n",
    "- utilisation des données sur les [chats et chiens](https://www.kaggle.com/c/dogs-vs-cats/data) sur kaggle\n",
    "\n",
    "On va utiliser ici des données qui sont issues de photos de chiens et chats sur kaggle, non normalisé, en couleurs, labelisée 0/1 (0=chat;1=chien).\n",
    "Les données ont été téléchargé via le lien kaggle données plus haut. \n",
    "Nous n'utiliserons que les 1000 première images de l'ensemble d'entrainement.\n",
    "\n",
    "## Ouverture des données création des dossiers\n",
    "\n",
    "Dans cette partie nous allons récupérer les données qui sont stockée dans un dossier contenant les images de chien et de chats\n",
    "créer un jeux de données plus petit contenant 1000 images d'entrainements pour chaque animaux, 500 donées de validation et 500 données d'entrainement soit au total 2000 données par animaux\n",
    "\n",
    "nous allons donc:\n",
    "- créer un nouveau dossier base_dir qui contiendra l'échantillonnage\n",
    "- ce dossier contiendra trois dossiers : train/validation/test\n",
    "- chacun de ces dossiers contiendra deux dossiers : cat et dog\n",
    "- nous déplacerons les données\n",
    "\n",
    "### Initialisation du dossier chat_vs_dog_data\n",
    "création du dossier qui contiendra l'échantillonnage du jeux de données d'origine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ac3ab23-92ff-4617-925d-6378cc2e8e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "# chemin datasets d'origine\n",
    "original_dataset_dir = \"/home/theo/Desktop/auto_formation_data/deeplwithpython/chat_vs_dog_data\"\n",
    "\n",
    "# nouveau dir qui contiendra des données \n",
    "base_dir = \"/home/theo/Desktop/auto_formation_data/deeplwithpython/cats_and_dogs_small\"\n",
    "shutil.rmtree(base_dir) # remove base_dir if it exist\n",
    "os.mkdir(base_dir)#crée le répertoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71161454-a4eb-42af-9987-fd769a5086d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# création des CHEMINS train, validation et test dans cats_and_dogs_small\n",
    "train_dir = os.path.join(base_dir,'train')\n",
    "validation_dir = os.path.join(base_dir,'validation')\n",
    "test_dir = os.path.join(base_dir,'test')\n",
    "\n",
    "os.mkdir(train_dir)\n",
    "os.mkdir(validation_dir)\n",
    "os.mkdir(test_dir)\n",
    "\n",
    "# creation of data directory for both cats and dogs in each previous directory (train, validation and test)\n",
    "rep = [train_dir,validation_dir,test_dir]\n",
    "\n",
    "list_dir_cat = list(map(lambda x: os.path.join(x,'cat'),rep))\n",
    "list_dir_dog = list(map(lambda x: os.path.join(x,'dog'),rep))\n",
    "\n",
    "list(map(lambda x: os.mkdir(x),list_dir_cat))\n",
    "list(map(lambda x: os.mkdir(x),list_dir_dog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e462811-8f15-487f-990d-9efa17cf54bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# création des jeux de données en déplacant les images du jeux de données d'entrainement original dans les nouveaux sous dossiers créés\n",
    "\n",
    "## pour les chats\n",
    "# création du jeux de données de'entrainement\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir,\"train/\"+fname)\n",
    "    dst = os.path.join(list_dir_cat[0],fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "    \n",
    "# création du jeux de données de validation*\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1000,1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir,\"train/\"+fname)\n",
    "    dst = os.path.join(list_dir_cat[1],fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "    \n",
    "# création du jeux de données de test*\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1500,2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir,\"train/\"+fname)\n",
    "    dst = os.path.join(list_dir_cat[2],fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "\n",
    "## pour les chiens\n",
    "# création du jeux de données de'entrainement\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir,\"train/\"+fname)\n",
    "    dst = os.path.join(list_dir_dog[0],fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "    \n",
    "# création du jeux de données de validation*\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000,1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir,\"train/\"+fname)\n",
    "    dst = os.path.join(list_dir_dog[1],fname)\n",
    "    shutil.copyfile(src,dst)\n",
    "    \n",
    "# création du jeux de données de test*\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1500,2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir,\"train/\"+fname)\n",
    "    dst = os.path.join(list_dir_dog[2],fname)\n",
    "    shutil.copyfile(src,dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a67390c-1532-43c4-9955-0e4535b2dcd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training cat images 1000\n",
      "total validation cat images 500\n",
      "total test cat images 500\n",
      "total training dog images 1000\n",
      "total validation dog images 500\n",
      "total test dog images 500\n"
     ]
    }
   ],
   "source": [
    "print(\"total training cat images {}\".format(len(os.listdir(list_dir_cat[0]))))\n",
    "print(\"total validation cat images {}\".format(len(os.listdir(list_dir_cat[1]))))\n",
    "print(\"total test cat images {}\".format(len(os.listdir(list_dir_cat[2]))))\n",
    "print(\"total training dog images {}\".format(len(os.listdir(list_dir_dog[0]))))\n",
    "print(\"total validation dog images {}\".format(len(os.listdir(list_dir_dog[1]))))\n",
    "print(\"total test dog images {}\".format(len(os.listdir(list_dir_dog[2]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece537bf-9dcc-4b79-8e85-bbc6142e9c78",
   "metadata": {},
   "source": [
    "# Architecture du jeux de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff4fc587-747f-4e7f-a02e-1719d96d54a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 34, 34, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 3,453,121\n",
      "Trainable params: 3,453,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import models,layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32,(3,3),activation=\"relu\",input_shape = (150,150,3)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64,(3,3),activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(128,(3,3),activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(128,(3,3),activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512,activation=\"relu\"))\n",
    "model.add(layers.Dense(1,activation=\"sigmoid\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c0ee58b-5df2-45e7-a3a6-6d674e6cca78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model.compile(optimizer = optimizers.RMSprop(lr=1e-4),\n",
    "             loss = \"binary_crossentropy\",\n",
    "             metrics = [\"acc\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711da59a-314c-40ae-afa9-c7c6b1939622",
   "metadata": {},
   "source": [
    "## Prétraitement des données\n",
    "il faut:\n",
    "- récupérer les images\n",
    "- les transformer en jeux de données de valeurs \n",
    "- transformer en tenseurs\n",
    "- minmaxscaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49b2f0bb-25b3-4483-91cc-0f7cef96468d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = (150,150),\n",
    "    batch_size = 20,\n",
    "    class_mode = 'binary')\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size = (150,150),\n",
    "    batch_size = 20,\n",
    "    class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d49a8bf4-9214-4cd4-b873-85117b402066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "100/100 [==============================] - 47s 457ms/step - loss: 0.6977 - acc: 0.5371 - val_loss: 0.6703 - val_acc: 0.6050\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 48s 481ms/step - loss: 0.6708 - acc: 0.5898 - val_loss: 0.6421 - val_acc: 0.6340\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 49s 487ms/step - loss: 0.6313 - acc: 0.6524 - val_loss: 0.6207 - val_acc: 0.6590\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 47s 473ms/step - loss: 0.6066 - acc: 0.6696 - val_loss: 0.5927 - val_acc: 0.6740\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 48s 482ms/step - loss: 0.5675 - acc: 0.6999 - val_loss: 0.5862 - val_acc: 0.6830\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 47s 474ms/step - loss: 0.5106 - acc: 0.7456 - val_loss: 0.5597 - val_acc: 0.6930\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 48s 478ms/step - loss: 0.4672 - acc: 0.7829 - val_loss: 0.6216 - val_acc: 0.6760\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 48s 485ms/step - loss: 0.4551 - acc: 0.7900 - val_loss: 0.5362 - val_acc: 0.7260\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 47s 472ms/step - loss: 0.4189 - acc: 0.8126 - val_loss: 0.5277 - val_acc: 0.7370\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 47s 467ms/step - loss: 0.3931 - acc: 0.8107 - val_loss: 0.5761 - val_acc: 0.7100\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 45s 454ms/step - loss: 0.3801 - acc: 0.8289 - val_loss: 0.5437 - val_acc: 0.7390\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 46s 462ms/step - loss: 0.3419 - acc: 0.8537 - val_loss: 0.5852 - val_acc: 0.7130\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 48s 477ms/step - loss: 0.3217 - acc: 0.8583 - val_loss: 0.5661 - val_acc: 0.7290\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 45s 455ms/step - loss: 0.2949 - acc: 0.8790 - val_loss: 0.5627 - val_acc: 0.7360\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 46s 460ms/step - loss: 0.2859 - acc: 0.8786 - val_loss: 0.7203 - val_acc: 0.7080\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 47s 471ms/step - loss: 0.2646 - acc: 0.8974 - val_loss: 0.6318 - val_acc: 0.7270\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 47s 469ms/step - loss: 0.2459 - acc: 0.9056 - val_loss: 0.7012 - val_acc: 0.7130\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 47s 470ms/step - loss: 0.2166 - acc: 0.9198 - val_loss: 0.6349 - val_acc: 0.7370\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 48s 476ms/step - loss: 0.1956 - acc: 0.9269 - val_loss: 0.6267 - val_acc: 0.7360\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 46s 461ms/step - loss: 0.1912 - acc: 0.9317 - val_loss: 0.6603 - val_acc: 0.7300\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 45s 452ms/step - loss: 0.1592 - acc: 0.9473 - val_loss: 0.7591 - val_acc: 0.7180\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 46s 458ms/step - loss: 0.1564 - acc: 0.9415 - val_loss: 0.6809 - val_acc: 0.7410\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 44s 444ms/step - loss: 0.1455 - acc: 0.9489 - val_loss: 0.7117 - val_acc: 0.7400\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 45s 447ms/step - loss: 0.1170 - acc: 0.9612 - val_loss: 0.8315 - val_acc: 0.7140\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 44s 445ms/step - loss: 0.0849 - acc: 0.9792 - val_loss: 0.7320 - val_acc: 0.7270\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 45s 450ms/step - loss: 0.0787 - acc: 0.9835 - val_loss: 0.7745 - val_acc: 0.7340\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 45s 448ms/step - loss: 0.0700 - acc: 0.9803 - val_loss: 0.7986 - val_acc: 0.7270\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 48s 476ms/step - loss: 0.0508 - acc: 0.9897 - val_loss: 0.8690 - val_acc: 0.7290\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 45s 453ms/step - loss: 0.0428 - acc: 0.9927 - val_loss: 0.9039 - val_acc: 0.7260\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 46s 456ms/step - loss: 0.0418 - acc: 0.9927 - val_loss: 0.9737 - val_acc: 0.7200\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch = 100,\n",
    "    epochs = 30,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f70ab104-ffa4-4f12-84d7-abf85169a63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cats_and_dogs_small_1.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
