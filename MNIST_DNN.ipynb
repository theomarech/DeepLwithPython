{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "substantial-merit",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown # permet d'intégrer du code markdown directement dans une section de code python classique avec Markdown(\"\"\"test\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tropical-negative",
   "metadata": {},
   "source": [
    "#  Introduction au réseau de neurones dense avec python (keras tensorflow)\n",
    "Chargement des données du jeux de données MNIST qui contient des images de chiffres en noir et blanc allant de 0 à 9. L'objectif dans une premier temps est d'utiliser un réseau de neurone dense pour la classification de ces images.\n",
    "Pour ça le jeux de données utilisé est chargé directement via keras. On donc par chargé les données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ceramic-cache",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le jeux de donnée d'entrainement contient 60000 images de dimensions (60000, 28, 28)\n",
      "le jeux de données de test contient 10000 images\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels),(test_images,test_labels) = mnist.load_data()\n",
    "\n",
    "print(\"le jeux de donnée d'entrainement contient {} images de dimensions {}\\nle jeux de données de test contient {} images\".format(train_images.shape[0], train_images.shape, test_images.shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amateur-cooper",
   "metadata": {},
   "source": [
    "Maintenant que nous avons charger le jeux de données nous pouvons chargé les fonction models et layers de keras qui nous permettrons de construire l'architecture du reseau de neurone dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "neutral-client",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation =\"relu\",input_shape=(28*28,)))\n",
    "network.add(layers.Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tropical-broadway",
   "metadata": {},
   "source": [
    "L'architecture du réseau est maintenant créée, elle correspond à un réseau de neurone séquentielle avec deux couches completement connectées, une première de 512 neurones avec une activation \"relu\" qui prend les données d'entrée à plat d'une dimension de 28*28, la seconde couche est la couche de sortie avec 10 neurones qui correspondent aux 10 chiffres (de 0 à 9) avec une activation softmax qui permet d'avoir les \"probabilités\" associées pour chaque entrée aux différents chiffres en sortie.\n",
    "Une fois l'architecture définit il reste à définir la compilation du modèle, c'est à dire l'optimiseur qui sera utilisé pour la descente de gradient stochastique (SGD), la métrique de perte qui sera optimisé par cette descente de gradient, dans le cas de notre classification à plusieurs classes, et différentes métriques de perte que nous voulons suivre le long de l'apprentissage afin d'évaluer le comportement de notre réseau (overfitting par exemple...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ecological-storage",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer = \"rmsprop\",\n",
    "                loss = \"categorical_crossentropy\",\n",
    "                metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "similar-allowance",
   "metadata": {},
   "source": [
    "Ensuite nous préparons les données : très important => les données doivent être normalisé ! dans le cas d'images X/max(X), ou Z score dans le cas de données quantitative classique. Il nous faut aussi mettre les données \"à plat\" cad passé du format image à un format tenseur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "alien-positive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nouvelle dimension des images (60000, 784),\n",
      "nouvelle valeur max des pixels des images 1.0\n"
     ]
    }
   ],
   "source": [
    "train_images, test_images = (train_images/train_images.max()).astype(float), (test_images/test_images.max()).astype(float)\n",
    "\n",
    "train_images, test_images = train_images.reshape((60000,28*28)), test_images.reshape((10000,28*28))\n",
    "\n",
    "print(\"nouvelle dimension des images {},\\nnouvelle valeur max des pixels des images {}\".format(train_images.shape,train_images.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "stone-thread",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "phantom-ancient",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.2580 - accuracy: 0.9241\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1036 - accuracy: 0.9690\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0690 - accuracy: 0.9788\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0512 - accuracy: 0.9844\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0380 - accuracy: 0.9886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19d0081c3a0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_images,train_labels,epochs=5,batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "printable-experience",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0681 - accuracy: 0.9807\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
