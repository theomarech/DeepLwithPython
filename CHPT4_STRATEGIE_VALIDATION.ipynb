{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beneficial-imaging",
   "metadata": {},
   "source": [
    "# CHPT IV - EVALUATION DES MODELES\n",
    "\n",
    "Objectif : trois techniques pour évaluer les modèles afin d'optimiser leur trade off biais/variance\n",
    "- avoir un modèles qui minimise/maximise un score\n",
    "- sur les données de test\n",
    "- sans les avoir vue au préalable\n",
    "\n",
    "Trois techniques :\n",
    "- simple hold-out validation = un training set splitté en training/validation et un test qu'on n'utilisera seulement avant la mise en production\n",
    "- shuffle hold-out avec iteration = on shuffle les données d'entrainement : on splitte train/validation on calcul l'erreur et on recommence...\n",
    "- KFOLD = dans le cas de petit jeux de données ou simplement dans le cas d'une variance forte dans le premier cas : on divise notre jeux de données en K partie de même taille, chaque partie sera prise comme jeux de données de validation et d'entrainement, les scores pourront alors être moyennée\n",
    "- KFOLD + shuffle iteration = les deux dernière technique, très bien pour les petits jeux de données mais très couteux en temps de calcul...\n",
    "\n",
    "D'autres techniques peuvent être envisager, notamment utiliser des échantillons bootstrap dans le shuffling dans le cas de très petit jeux de données...\n",
    "\n",
    "\n",
    "\n",
    "## Préparation des données et du modèles sur les données imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "robust-champagne",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "C:\\Users\\marec\\miniconda3\\envs\\deeplwithpython\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "C:\\Users\\marec\\miniconda3\\envs\\deeplwithpython\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras import models, layers\n",
    "import numpy as np\n",
    "\n",
    "#ouverture\n",
    "(train_data,train_labels),(test_data,test_labels) = imdb.load_data(num_words=10000)\n",
    "\n",
    "#prépa des données train et test\n",
    "def vectorize_data(data,dim=10000):\n",
    "    results = np.zeros((len(data),dim))\n",
    "    for i, word in enumerate(data):\n",
    "        results[i,word] = 1\n",
    "    return results\n",
    "\n",
    "x_train = vectorize_data(train_data)\n",
    "x_test = vectorize_data(test_data)\n",
    "\n",
    "y_train = np.asarray(train_labels).astype(float)\n",
    "y_test = np.asarray(test_labels).astype(float)\n",
    "\n",
    "# réseaux de neurones\n",
    "\n",
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(16,activation = \"relu\",input_shape = (10000,)))\n",
    "    model.add(layers.Dense(16,activation = \"relu\"))\n",
    "    model.add(layers.Dense(1, activation = \"sigmoid\"))\n",
    "    \n",
    "    model.compile(optimizer = \"rmsprop\",\n",
    "                  loss = \"binary_crossentropy\",\n",
    "                  metrics = [\"accuracy\"])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unusual-pressing",
   "metadata": {},
   "source": [
    "## Simple hold-out validation\n",
    "\n",
    "Ce protocole d'apprentissage marche bien, le seul problème est qu'il faut suffisamment de données pour avoir trois jeux de données représentatif avec un jeux de données train suffisant pour l'apprentissage. On peut identifier des problèmes si on observe de grand changement de prédiction entre chaque shuffling des données, à ce moment là il est nécessaire de passer à un système KFOLD avec ou sans randomisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "armed-examination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "37/37 [==============================] - 1s 25ms/step - loss: 0.4328 - accuracy: 0.8335 - val_loss: 0.2746 - val_accuracy: 0.9256\n",
      "Epoch 2/5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 0.1938 - accuracy: 0.9508 - val_loss: 0.1661 - val_accuracy: 0.9506\n",
      "Epoch 3/5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 0.1079 - accuracy: 0.9727 - val_loss: 0.1316 - val_accuracy: 0.9565\n",
      "Epoch 4/5\n",
      "37/37 [==============================] - 1s 18ms/step - loss: 0.0661 - accuracy: 0.9854 - val_loss: 0.0968 - val_accuracy: 0.9706\n",
      "Epoch 5/5\n",
      "37/37 [==============================] - 1s 17ms/step - loss: 0.0398 - accuracy: 0.9917 - val_loss: 0.0911 - val_accuracy: 0.9717\n",
      "196/196 [==============================] - 0s 1ms/step - loss: 0.0911 - accuracy: 0.9717\n",
      "Epoch 1/5\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.3914 - accuracy: 0.8662\n",
      "Epoch 2/5\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.1529 - accuracy: 0.9605\n",
      "Epoch 3/5\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0829 - accuracy: 0.9798\n",
      "Epoch 4/5\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.0479 - accuracy: 0.9891\n",
      "Epoch 5/5\n",
      "49/49 [==============================] - 1s 16ms/step - loss: 0.0290 - accuracy: 0.9942\n",
      "782/782 [==============================] - 1s 2ms/step - loss: 0.4575 - accuracy: 0.8614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.45751768350601196, 0.8614400029182434]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# important de mélanger le jeux de données dans le cas où il est n'est pas séquentielle (genre données temporelles quoi) avec np.random.shuffle()\n",
    "# problème c'est que ca mélange aléatoirement les ligne de l'array mais ici on a train et test donc on va utiliser les indices plutot\n",
    "\n",
    "indice_train = np.random.choice(np.arange(0,len(x_train)),len(x_train))\n",
    "\n",
    "x_train = x_train[indice_train]\n",
    "y_train = y_train[indice_train]\n",
    "\n",
    "# on coupe en train validation\n",
    "p = 0.75\n",
    "l = len(x_train)\n",
    "size = round(p*l)\n",
    "\n",
    "x_ent = x_train[:size]\n",
    "y_ent = y_train[:size]\n",
    "\n",
    "x_val = x_train[size:]\n",
    "y_val = y_train[size:]\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "model.fit(x_ent,\n",
    "          y_ent,\n",
    "          epochs=5,\n",
    "          batch_size=512,\n",
    "         validation_data=(x_val,y_val))\n",
    "\n",
    "model.evaluate(x_val,y_val)\n",
    "## et la on continue pour améliorer notre modèle en revenant sur les hyperparamètres: la capacité (nombre de couche,nombre d'unité), le nombre d'epoch, le batch_size, la régularisation, le dropout, le type de couche\n",
    "## ensuite, quand on est sur que notre modèle est optimisé en terme de précision et de généralisation on entraine sur tout le jeux de données et on test sur le jeux de donnée de test\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "model.fit(x_train,y_train, epochs = 5, batch_size=512)\n",
    "\n",
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-adapter",
   "metadata": {},
   "source": [
    "## Validation croisée à K fold\n",
    "\n",
    "L'objectif est de couper le jeux de données d'entrainement en K morceaux de même taille qui deviendront tour à tour jeux de données de test (un morceau) vs tous les autres morceaux en entrainement. L'avantage de ce type d'approche et d'obtenir des scores moyens et donc avoir une idée plus précise de la gé\n",
    "néralisation dans le cas de jeux de données moyen/petit ainsi qu'avoir une idée de la variance associée au modèle. Un peu plus couteux en temps de calcul puisqu'il faudra faire tourner le modèle K fois.\n",
    "On peut coupler cette technique avec un hold out si la taille du jeux de données le permet c'est toujours mieux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "potential-orbit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.5212 - accuracy: 0.8088\n",
      "Epoch 2/5\n",
      "25/25 [==============================] - 0s 14ms/step - loss: 0.2663 - accuracy: 0.9574\n",
      "Epoch 3/5\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 0.1434 - accuracy: 0.9793\n",
      "Epoch 4/5\n",
      "25/25 [==============================] - 0s 14ms/step - loss: 0.0812 - accuracy: 0.9877\n",
      "Epoch 5/5\n",
      "25/25 [==============================] - 0s 14ms/step - loss: 0.0455 - accuracy: 0.9934\n",
      "196/196 [==============================] - 0s 1ms/step - loss: 0.0728 - accuracy: 0.9802\n",
      "Epoch 1/5\n",
      "25/25 [==============================] - 0s 14ms/step - loss: 0.5579 - accuracy: 0.7768\n",
      "Epoch 2/5\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 0.3180 - accuracy: 0.9534\n",
      "Epoch 3/5\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 0.1689 - accuracy: 0.9746\n",
      "Epoch 4/5\n",
      "25/25 [==============================] - 0s 14ms/step - loss: 0.0901 - accuracy: 0.9862\n",
      "Epoch 5/5\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.0519 - accuracy: 0.9926\n",
      "196/196 [==============================] - 0s 1ms/step - loss: 0.0741 - accuracy: 0.9795\n",
      "Epoch 1/5\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.4849 - accuracy: 0.8023\n",
      "Epoch 2/5\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 0.2151 - accuracy: 0.9610\n",
      "Epoch 3/5\n",
      "25/25 [==============================] - 0s 14ms/step - loss: 0.1097 - accuracy: 0.9838\n",
      "Epoch 4/5\n",
      "25/25 [==============================] - 0s 14ms/step - loss: 0.0613 - accuracy: 0.9906\n",
      "Epoch 5/5\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.0333 - accuracy: 0.9958\n",
      "196/196 [==============================] - 0s 2ms/step - loss: 0.0727 - accuracy: 0.9806\n"
     ]
    }
   ],
   "source": [
    "## Shuffling des données d'entrainement\n",
    "indice = np.random.choice(np.arange(0,len(x_train)),len(x_train))\n",
    "x_train = x_train[indice]\n",
    "y_train = y_train[indice]\n",
    "\n",
    "## Hold out pour la validation\n",
    "p = 0.75\n",
    "l = len(x_train)\n",
    "size = round(0.75*l)\n",
    "\n",
    "x_ent = x_train[:size]\n",
    "y_ent = y_train[:size]\n",
    "x_val = x_train[size:]\n",
    "y_val = y_train[size:]\n",
    "\n",
    "## K fold\n",
    "K = 3 # nombre de fold\n",
    "K_size = len(x_ent)//K # taille de chaque fold\n",
    "result_fold = [] # stockage des résultats de performance de chaque fold\n",
    "\n",
    "for i in range(K):\n",
    "    x_fold_train = np.concatenate([x_ent[:i*K_size],x_ent[(i+1)*K_size:]])\n",
    "    y_fold_train = np.concatenate([y_ent[:i*K_size],y_ent[(i+1)*K_size:]])\n",
    "\n",
    "    x_fold_test = x_ent[i*K_size:(i+1)*K_size]\n",
    "    y_fold_test = y_ent[i*K_size:(i+1)*K_size]\n",
    "    \n",
    "    model = build_model()\n",
    "    model.fit(x_fold_train,\n",
    "             y_fold_train,\n",
    "             epochs = 5,\n",
    "             batch_size = 512)\n",
    "    \n",
    "    validation_score = model.evaluate(x_fold_test,y_fold_test)\n",
    "    result_fold.append(validation_score)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "focused-surgery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07322385, 0.98010667])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(result_fold).mean(axis=0) # la moyenne de la perte et de l'accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "least-combining",
   "metadata": {},
   "source": [
    "## Validation shuffling et kfold\n",
    "- ici on va utiliser deux techniques: une randomisation des données puis kfold\n",
    "- bien pour les petits jeux de données\n",
    "- très computing consuming = N * K model à entrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "imposed-sleep",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "33/33 [==============================] - 0s 15ms/step - loss: 0.3968 - accuracy: 0.8654\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.1380 - accuracy: 0.9758\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0606 - accuracy: 0.9914\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.0273 - accuracy: 0.9967\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0114 - accuracy: 0.9990\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0185 - accuracy: 0.9947\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 0s 15ms/step - loss: 0.4087 - accuracy: 0.8653\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.1482 - accuracy: 0.9723\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0672 - accuracy: 0.9910\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 15ms/step - loss: 0.0310 - accuracy: 0.9959\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0137 - accuracy: 0.9987\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.0185 - accuracy: 0.9957\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.4174 - accuracy: 0.8646\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 15ms/step - loss: 0.1574 - accuracy: 0.9742\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 15ms/step - loss: 0.0718 - accuracy: 0.9896\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.0328 - accuracy: 0.9958\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0145 - accuracy: 0.9984\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.0197 - accuracy: 0.9947\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 0s 15ms/step - loss: 0.3845 - accuracy: 0.8739\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.1346 - accuracy: 0.9800\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0592 - accuracy: 0.9911\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 15ms/step - loss: 0.0269 - accuracy: 0.9962\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0123 - accuracy: 0.9984\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.0241 - accuracy: 0.9947\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.4597 - accuracy: 0.8387\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 15ms/step - loss: 0.1730 - accuracy: 0.9722\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0761 - accuracy: 0.9892\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0348 - accuracy: 0.9946\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0167 - accuracy: 0.9979\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.0306 - accuracy: 0.9904\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 1s 15ms/step - loss: 0.4491 - accuracy: 0.8469\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.1740 - accuracy: 0.9733\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0816 - accuracy: 0.9871\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0389 - accuracy: 0.9945\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0190 - accuracy: 0.9969\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.0267 - accuracy: 0.9918\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 1s 17ms/step - loss: 0.4466 - accuracy: 0.8523\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.1646 - accuracy: 0.9755\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 1s 18ms/step - loss: 0.0718 - accuracy: 0.9901\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0334 - accuracy: 0.9954\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 1s 16ms/step - loss: 0.0159 - accuracy: 0.9980\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0515 - accuracy: 0.9914\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 0s 15ms/step - loss: 0.3921 - accuracy: 0.8771\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 15ms/step - loss: 0.1436 - accuracy: 0.9779\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 15ms/step - loss: 0.0643 - accuracy: 0.9901\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 14ms/step - loss: 0.0290 - accuracy: 0.9957\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0132 - accuracy: 0.9981\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.0350 - accuracy: 0.9899\n",
      "Epoch 1/5\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.4294 - accuracy: 0.8654\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 0s 15ms/step - loss: 0.1626 - accuracy: 0.9749\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 0s 15ms/step - loss: 0.0713 - accuracy: 0.9906\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 0s 15ms/step - loss: 0.0322 - accuracy: 0.9956\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 0s 13ms/step - loss: 0.0142 - accuracy: 0.9981\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.0367 - accuracy: 0.9890\n"
     ]
    }
   ],
   "source": [
    "N = 3 # nombre de shuffling à réaliser\n",
    "K = 3 # nombre de fold\n",
    "\n",
    "epoch = 5\n",
    "batch_size = 512\n",
    "\n",
    "#splitte en évaluation entrainement\n",
    "p = 0.75\n",
    "l = len(x_train)\n",
    "size = round(p*l)\n",
    "\n",
    "x_ent = x_train[:size]\n",
    "y_ent = y_train[:size]\n",
    "\n",
    "x_val = x_train[size:]\n",
    "y_val = y_train[size:]\n",
    "\n",
    "# boucle shuffling + boucle kfold\n",
    "for n in range(N):\n",
    "    indice = np.random.choice(np.arange(0,len(x_ent)),len(x_ent))\n",
    "    x_ent_rand = x_ent[indice]\n",
    "    y_ent_rand = y_ent[indice]\n",
    "    validation_metric = np.zeros((N,K))\n",
    "    k_size = len(x_train)//K\n",
    "    for k in range(K):\n",
    "        x_train_fold = np.concatenate([x_ent_rand[:i*k_size],x_ent_rand[(i+1)*k_size:]])\n",
    "        y_train_fold = np.concatenate([y_ent_rand[:i*k_size],y_ent_rand[(i+1)*k_size:]])\n",
    "        \n",
    "        x_test_fold = x_ent_rand[i*k_size:(i+1)*k_size]\n",
    "        y_test_fold = y_ent_rand[i*k_size:(i+1)*k_size]\n",
    "        \n",
    "        model = build_model()\n",
    "        \n",
    "        model.fit(x_train_fold,\n",
    "                  y_train_fold,\n",
    "                 epochs = epoch,\n",
    "                 batch_size = batch_size,\n",
    "                 verbose = 0)\n",
    "        \n",
    "        validation_metric[n,k] = model.evaluate(x_test_fold,y_test_fold)[1]\n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
